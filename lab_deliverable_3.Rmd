---
title: "Lab_deliverable_3"
author: "Yihang Duanmu, Minjun Kim, Annelise Schreiber"
date: "2025-10-22"
output:
  html_document:
    css: styles.css
  word_document:
    reference_docx: tnr_12pt.docx
  pdf_document:
    latex_engine: xelatex
classoption: 12pt
header-includes:
  - \usepackage{fontspec}
  - \setmainfont{Times New Roman}
  - \setsansfont{Times New Roman}
  - \setmonofont{Courier New}
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,fontsize=\scriptsize,commandchars=\\\{\}}
  - \DefineVerbatimEnvironment{verbatim}{Verbatim}{breaklines,fontsize=\scriptsize}
---

```{r}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.width = 5.8, fig.height = 3.3, dpi = 220)
```

```{r}
# Install-once helper
need <- c("tidyverse","janitor","readr","broom","kableExtra","lubridate","skimr","patchwork")
to_get <- setdiff(need, rownames(installed.packages()))
if (length(to_get)) install.packages(to_get, Ncpus = 2)

library(tidyverse); library(janitor); library(readr)
library(broom); library(kableExtra); library(skimr); library(patchwork)

theme_set(theme_minimal(base_family = "Times New Roman"))
```

```{r}
fname <- if (file.exists("dataset_Facebook.csv")) "dataset_Facebook.csv" else "facebook_updated.csv"

fb_raw <- if (basename(fname) == "dataset_Facebook.csv") {
  read_delim(fname, delim = ";", show_col_types = FALSE)
} else {
  read_csv(fname, show_col_types = FALSE)
}

fb <- fb_raw |>
  clean_names() |>
  mutate(
    post_month   = suppressWarnings(as.integer(post_month)),
    post_weekday = suppressWarnings(as.integer(post_weekday)),
    post_hour    = suppressWarnings(as.integer(post_hour)),
    paid         = if_else(is.na(paid), 0L, as.integer(paid)),
    lifetime_post_consumers       = suppressWarnings(as.numeric(lifetime_post_consumers)),
    lifetime_post_total_reach     = suppressWarnings(as.numeric(lifetime_post_total_reach)),
    lifetime_post_total_impressions = suppressWarnings(as.numeric(lifetime_post_total_impressions))
  )

wk_labels <- c("Mon","Tue","Wed","Thu","Fri","Sat","Sun")
fb <- fb |>
  mutate(
    wday_fac  = factor(post_weekday, levels = 1:7, labels = wk_labels, ordered = TRUE),
    hour_fac  = factor(post_hour, levels = sort(unique(post_hour)), ordered = TRUE),
    month_fac = factor(post_month, levels = 1:12, labels = month.abb, ordered = TRUE),
    paid_fac  = factor(if_else(paid == 1, "Paid", "Unpaid"), levels = c("Unpaid","Paid"))
  )
```

```{r}
miss_tbl <- tibble(
  variable = names(fb),
  n_miss   = colSums(is.na(fb))
) |> arrange(desc(n_miss))

# Simple sanity filters (keep data; just flag)
summary_cols <- fb |>
  select(lifetime_post_consumers, lifetime_post_total_reach,
         like, share, comment, paid, post_hour, post_weekday, post_month)

list(
  head_missing = head(miss_tbl, 10),
  quick_summary = summary(summary_cols)
)
```

```{r}
core <- fb |>
  transmute(
    consumers = lifetime_post_consumers,
    reach     = lifetime_post_total_reach,
    likes     = like, shares = share, comments = comment,
    paid      = paid_fac, hour = post_hour, weekday = wday_fac, month = month_fac
  )

library(skimr)

skim_tbl <- skim(core |> select(consumers, reach, likes, shares, comments)) |>
  select(skim_variable, n_missing,
         numeric.mean, numeric.sd,
         numeric.p0, numeric.p25, numeric.p50, numeric.p75, numeric.p100) |>
  dplyr::rename(mean = numeric.mean, sd = numeric.sd,
                p0 = numeric.p0, p25 = numeric.p25, p50 = numeric.p50,
                p75 = numeric.p75, p100 = numeric.p100)

skim_tbl |>
  kableExtra::kbl(caption = "Descriptive statistics (key variables)") |>
  kableExtra::kable_classic(full_width = FALSE)
```

```{r}
dat <- fb |>
  transmute(
    consumers = as.numeric(lifetime_post_consumers),
    reach     = as.numeric(lifetime_post_total_reach),
    paid      = paid_fac,
    paid_fac  = paid_fac,

    hour   = hour_fac,
    wday   = wday_fac,
    month  = month_fac,
    idx    = dplyr::row_number()
  ) |>
  mutate(
    y_log_eng   = log1p(consumers),
    y_log_reach = log1p(reach),
    hour_num    = as.numeric(as.character(hour)),
    mon_num     = as.integer(month)
  ) |>
  mutate(
    paid_fac = forcats::fct_relevel(paid_fac, "Unpaid", "Paid"),
    paid     = paid_fac
  )

summary(dplyr::select(dat, consumers, reach, y_log_eng, y_log_reach)) |>
  kableExtra::kbl(caption = "Outcome summaries after log1p construction") |>
  kableExtra::kable_classic(full_width = FALSE)

```

##Lab 3: Question 1

Question. Does the time of day a post is made impact engagement, after controlling for weekday, month, paid status, content type/category, and page size?

Response (Y): log1p(consumers) — log-transform stabilizes variance and downweights a few very large posts.

Covariates (X):
hour_num = post hour (0–23, numeric),
paid_fac = Paid vs Unpaid,
Controls: wday_fac (Mon–Sun), mon_num (1–12), type_fac (post type), cat_fac (category), and log_page_likes (log of page_total_likes)

```{r}
ggplot(dat, aes(x = hour_num, y = y_log_eng, color = paid_fac)) +
geom_point(alpha = 0.35, shape = 16, size = 1.6,
position = position_jitter(width = 0.25, height = 0)) +
geom_smooth(method = "lm", se = FALSE, linewidth = 1.1) +
scale_color_manual(values = c("grey40", "steelblue4"), name = "Paid Status") +
labs(title = "Predicted Engagement by Paid Status and Post Hour",
x = "Post Hour", y = "log(Consumers + 1)") +
theme_minimal(base_size = 12) +
theme(legend.position = "right")
```
The scatter with fitted lines shows only a very small increase in engagement (log(1+consumers)) as posting hour gets later. The “Paid” line sits slightly above the “Unpaid” line across most hours, suggesting paid posts tend to draw marginally higher engagement, but the two lines are nearly overlapping and the point cloud is wide—so the hour effect is weak and the paid vs. unpaid gap is modest relative to the variability. In short: posting time has little practical impact, and paying helps a bit, but neither factor explains much of the dispersion.

```{r}
# Multiple linear regression with interaction

m_q1 <- lm(y_log_eng ~ paid_fac + hour_num + paid_fac:hour_num, data = dat)

# Nice coefficient table

tbl_q1_coef <- broom::tidy(m_q1, conf.int = TRUE) |>
dplyr::mutate(dplyr::across(where(is.numeric), ~ round(., 4)),
term = gsub("paid_fac", "paid:", term))

# Model fit stats

tbl_q1_fit <- broom::glance(m_q1) |>
dplyr::mutate(dplyr::across(where(is.numeric), ~ round(., 4))) |>
dplyr::select(r.squared, adj.r.squared, sigma, statistic, p.value, df, nobs)

# Show

kableExtra::kbl(tbl_q1_coef,
caption = "Q1 Multiple OLS: log(Consumers+1) ~ Paid + Hour + Paid×Hour") |>
kableExtra::kable_classic(full_width = FALSE)

kableExtra::kbl(tbl_q1_fit, caption = "Q1 Model fit") |>
kableExtra::kable_classic(full_width = FALSE)

# (Optional) show the base R summary like your teammate did

# summary(m_q1)

```
The multiple-linear model log(Consumers + 1) ~ Paid + Hour + Paid X Hour explains very little of the variation in engagement (R^2 = 0.014; adj. R^2 = 0.008). For unpaid posts at hour 0, the expected log engagement is ~6.13. The main effect for Paid is 0.247 (95% CI: [-0.106, 0.6], p = 0.17), which on the original scale corresponds to roughly +28% consumers (e^0.247 - 1) at hour 0, but the CI includes zero, so it's not statistically significant. The Hour slope is 0.0144 per hour (CI [-0.0067, 0.0356], p = 0.18), about +1.4% per additional hour for unpaid posts - again not significant. The interaction -0.0052 (p = 0.80) suggests the hour effect is slightly smaller for paid posts, but this is also not significant. Overall, posting hour and paid status (and their interaction) show no reliable association with engagement in this dataset; other variables likely drive the differences in consumer counts.



##Lab 3: Question 2

Question: Does the time that a post is made during the day, coupled with the post being paid or not, impact the reach that a post gets?

Response variable (Y): "consumers"
  - This represents lifetime post consumers, a numerical value.
  
Covariates: 
"paid"
  - This is a binary variable (e.g., 1 for paid posts, 0 for unpaid). It allows us to compare the average reach between the two groups.
"post_hour"
  - This variable represents the time of day a post was made.

Since we want to see whether the hour of a post and paid status impacts average reach, a multiple linear regression model is appropriate with paid status and post hour as the independent variables, and lifetime consumers as the response. This variable was used to represent reach as we felt the number of consumers of a post best represented overall reach.

```{r Lab 3}

dat$paid <- as.numeric(dat$paid)
dat$hour <- as.numeric(as.character(dat$hour))
model <- lm(log1p(consumers) ~ paid + hour, data = dat)

pred_dat <- expand.grid(
  paid = c(0, 1),
  hour = seq(min(dat$hour), max(dat$hour), length.out = 50)
)

pred_dat$pred <- predict(model, newdata = pred_dat)

ggplot(dat, aes(x = hour, y = log1p(consumers), color = factor(paid))) +
  geom_point(alpha = 0.4, size = 1) +
  geom_line(data = pred_dat, aes(y = pred, color = factor(paid)), size = 1.2) +
  labs(
    title = "Predicted Consumers by Paid Status and Post Hour",
    x = "Post Hour",
    y = "Log(Consumers + 1)",
    color = "Paid Status"
  ) +
  scale_color_manual(values = c("0" = "#1f77b4", "1" = "#ff7f0e"),
                     labels = c("Unpaid", "Paid")) +
  theme_minimal()

```

Multiple Linear Regression Model:
log(Consumersi+1)=β0+β1(Paidi)+β2(Houri)+εi
β1 represents the expected change in the response as a result of a post being paid as opposed to unpaid; β0 represents the expected change in the response as the result of each added hour in the day that a post is made.

Assumptions: linear relationships between the predictors and the response; independent observations; constant variance of residuals; and normally distributed errors.

```{r Lab 3 pt 2}

  summary(model)

```
From this data, we're able to have some insight on the research question. It seems as though the influence of a post being paid or not is statistically significant regarding a post's reach, but the hour in which the post is made is not significant. From the adjusted R squared value of 0.009859, we can tell that only about 0.9895% of the variance in log consumers can be accounted for by theses factors--other factors are likely to be more influential.

Illustration of Model Fit:
```{r Lab 3 pt 3}

#Residuals vs Fitted

library(ggplot2)
library(broom)

resid_df <- augment(model)

ggplot(resid_df, aes(.fitted, .resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted Values", y = "Residuals", title = "Residuals vs Fitted") +
  theme_minimal()

#QQ Plot

ggplot(resid_df, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Normal Q-Q Plot") +
  theme_minimal()

```
From these graphs, can see that the normality assumption generally holds except at the tails where there seems to be outliers. From the residuals vs fitted graph we can see that linearity holds as the points are approximately scattered about 0 without a clear pattern.
